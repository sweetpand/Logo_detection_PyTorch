{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logo recognition networks | Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetpand/Logo_detection_PyTorch/blob/master/Logo_recognition_networks_%7C_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug2BtcBlIyc6",
        "colab_type": "text"
      },
      "source": [
        "# Download and import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ri4_hlAIQNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu100' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "%matplotlib inline\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZiMh3AhJvXT",
        "colab_type": "text"
      },
      "source": [
        "#Download the training, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqeE_XOFI6C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/FlickrLogos-32_dataset_v2\" -d \"/content/dataset\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKAGpn2b4otz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www.multimedia-computing.de/flickrlogos/data/FlickrLogos-32_dataset_v2.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBcp02kRiaqK",
        "colab_type": "text"
      },
      "source": [
        "# Train the network function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsdoXiN3H4A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val(model, criterion, optimizer, num_epochs=20):\n",
        "    since = time.time()\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoc {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Forward pass\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # Compute loss\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Compute gradients and update parameters if train\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size()[0]\n",
        "                running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "            epoch_loss = running_loss / len(datasets[phase])\n",
        "            epoch_acc = running_corrects / len(datasets[phase])\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "                print('##: {}', train_losses)\n",
        "            else:\n",
        "                val_losses.append(epoch_loss)\n",
        "                print('##: {}', val_losses)\n",
        "        \n",
        "            print('{} Loss: {:.4f} Acc.: {:.2f} %'.format(\n",
        "                phase.title(), epoch_loss, epoch_acc * 100))\n",
        "        \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print()\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Accuracy: {:.2f} %'.format(best_acc * 100))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm-3rcj8Kd77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_FENi4ciq60",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Z39yXQi02F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = Path(\"dataset/FlickrLogos-v2/classes/jpg\")\n",
        "SETS = ['train', 'val', 'test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnl3by7p-YtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOURCE_DIR = Path('dataset/FlickrLogos-v2')\n",
        "DATA_DIR = Path('data')\n",
        "SETS = ['train', 'val', 'test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H5uNzRH-kqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_datasets(url, dst_dir):\n",
        "    zip_file = url.split(sep='/')[-1]\n",
        "    if not dst_dir.is_dir():\n",
        "        if not zip_file.is_file():\n",
        "            urllib.request.urlretrieve(url, zip_file)        \n",
        "        with zipfile.ZipFile(zip_file) as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "        #os.unlink(zip_file)    # comment out if you want to delete zip file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzeFwKBj3-Se",
        "colab_type": "text"
      },
      "source": [
        "#Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V7Tndnc-vKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_datasets(src_dir, dst_dir, keep_source=True):\n",
        "    for dataset, paths in dataset_paths.items():\n",
        "        num_files = 0\n",
        "        for path in paths:\n",
        "            num_files += 1\n",
        "            src = src_dir / path\n",
        "            dst = dst_dir / (path.replace('classes/jpg', dataset))\n",
        "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(src, dst)\n",
        "        print(dataset, 'dataset:', str(num_files))\n",
        "    if not keep_source: shutil.rmtree(src_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM9czn0R_KLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_image_paths(txt_relpath):\n",
        "    with open(txt_relpath) as f:\n",
        "        image_paths = f.read().splitlines()\n",
        "    return image_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjVEe99__Kwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_logo_relpaths = list_image_paths(SOURCE_DIR / 'trainset.relpaths.txt')\n",
        "val_logo_relpaths = list_image_paths(SOURCE_DIR / 'valset-logosonly.relpaths.txt')\n",
        "val_nologo_relpaths = list_image_paths(SOURCE_DIR / 'valset-nologos.relpaths.txt')\n",
        "test_relpaths = list_image_paths(SOURCE_DIR / 'testset.relpaths.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uiESdIn_Fio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_relpaths = train_logo_relpaths + val_nologo_relpaths[:int(len(val_nologo_relpaths) / 2)]\n",
        "val_relpaths = val_logo_relpaths + val_nologo_relpaths[int(len(val_nologo_relpaths) / 2):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eJwsy-Z_CO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relpaths = [train_relpaths, val_relpaths, test_relpaths]\n",
        "dataset_paths = dict(zip(SETS, relpaths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu68C9iG-0Vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepare_datasets(SOURCE_DIR, DATA_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_037-JVgKGr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mean = np.array([0.485, 0.456, 0.406])\n",
        "train_std = np.array([0.229, 0.224, 0.225])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OajLdE6l1rSW",
        "colab_type": "text"
      },
      "source": [
        "##Make to change resize to 299X299 for INCEPTION_V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPTTFA-7Skzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((224, 224)), \n",
        "#     transforms.Resize((299, 299)), inception\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilhvWVBAKJdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = {i : torchvision.datasets.ImageFolder(DATA_DIR / i, data_transforms) \n",
        "            for i in ['train', 'val', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9wodGi8KL-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bz = 8\n",
        "dataloaders = {i : DataLoader(datasets[i], batch_size=bz, shuffle=(i == 'train'), num_workers=0) \n",
        "               for i in ['train', 'val', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRzJE3PQ5WrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy().transpose((1, 2, 0))\n",
        "    npimg = npimg * train_std + train_std    # denorm\n",
        "    npimg = np.clip(npimg, 0, 1)\n",
        "    plt.imshow(npimg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDvmD0KQKRsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, labels = next(iter(dataloaders['train']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdr39EsxKT0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = torchvision.utils.make_grid(imgs[:4])\n",
        "classes = datasets['train'].classes\n",
        "print(', '.join(classes[i] for i in labels[:4]))\n",
        "imshow(img)\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ddJclJD2AnB",
        "colab_type": "text"
      },
      "source": [
        "###SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4OREt_VKWYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torchvision.models.squeezenet1_0(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc075jwz2FN3",
        "colab_type": "text"
      },
      "source": [
        "###Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWWMN2I2LFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torchvision.models.inception_v3(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 100)\n",
        "model_ft.aux_logits=False # inception\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv0_EGaS2mRz",
        "colab_type": "text"
      },
      "source": [
        "###ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ3qLHzR2pBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torchvision.models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 100)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDGhX--f23F6",
        "colab_type": "text"
      },
      "source": [
        "###GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FymeNjSW25Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torchvision.models.googlenet(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3TSe4wz3GK-",
        "colab_type": "text"
      },
      "source": [
        "###VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cwu9J543I-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torchvision.models.vgg16(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU1wjASujKcB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "# Train the network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4sOPMtDKYKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "\n",
        "%time model_ft = train_val(model_ft, criterion, optimizer_ft)\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr4KlxZCj00f",
        "colab_type": "text"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPPekyGuj55L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_ft, 'logo_NameOfTheNetwork.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}